{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wy4_1rHqqQX3",
        "outputId": "b0021c68-47ea-4a71-8be2-44f331a45728"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment of the tweet: 0\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "import nltk\n",
        "\n",
        "# Define the identity preprocessor function again\n",
        "def identity_preprocessor(text):\n",
        "    return text  # No processing, just return the input text\n",
        "\n",
        "# Redefine the custom tokenizer function used during the vectorizer fitting\n",
        "def custom_tokenizer(text):\n",
        "    return text.split()  # Tokenize by splitting on spaces (you can use a more sophisticated tokenizer if needed)\n",
        "\n",
        "# Load the saved vectorizer, model, and scaler\n",
        "cv = joblib.load('vectorizer.pkl')\n",
        "model_lr_cv = joblib.load('logistic_regression_model.pkl')\n",
        "scaler = joblib.load('scaler.pkl')\n",
        "\n",
        "# Define a function for predicting sentiment of a new tweet\n",
        "def predict_sentiment(tweet):\n",
        "    # Step 1: Tokenize the tweet (split the text into words)\n",
        "    tweet_tokens = tweet.split()  # Assuming the tweet is already tokenized\n",
        "\n",
        "    # Step 2: Transform the tokens using the saved vectorizer\n",
        "    tweet_cv = cv.transform([' '.join(tweet_tokens)])  # Convert the list of tokens to a string and transform\n",
        "\n",
        "    # Step 3: Scale the transformed data using the saved scaler\n",
        "    tweet_scaled = scaler.transform(tweet_cv)\n",
        "\n",
        "    # Step 4: Predict sentiment using the saved model\n",
        "    sentiment_prediction = model_lr_cv.predict(tweet_scaled)\n",
        "\n",
        "    # Return the sentiment prediction (e.g., positive or negative)\n",
        "    return sentiment_prediction[0]\n",
        "\n",
        "# Example usage\n",
        "tweet = \"I  machine u good better, bad not good !\"\n",
        "sentiment = predict_sentiment(tweet)\n",
        "\n",
        "# Print the result\n",
        "print(f\"Sentiment of the tweet: {sentiment}\")\n"
      ]
    }
  ]
}